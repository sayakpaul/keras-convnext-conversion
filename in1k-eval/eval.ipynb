{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926bae46",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf2cddc-fdb8-4efb-acce-14bd17afd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae636ae-24d1-4523-9997-696731318a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from imutils import paths\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f0a2",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8238055-08bf-44e1-8f3b-98e7768f1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 256\n",
    "IMAGE_SIZE = 224\n",
    "BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f52f8a4-be56-4a32-843c-18639f010384",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"tiny\": {\n",
    "        \"depths\": [3, 3, 9, 3],\n",
    "        \"projection_dims\": [96, 192, 384, 768],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"small\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [96, 192, 384, 768],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"base\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [128, 256, 512, 1024],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [192, 384, 768, 1536],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"xlarge\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [256, 512, 1024, 2048],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115b327f-b60b-459f-a51d-45d2c6b09565",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_HASHES = {\n",
    "  \"tiny\":\n",
    "    (\"8ae6e78ce2933352b1ef4008e6dd2f17bc40771563877d156bc6426c7cf503ff\",\n",
    "      \"d547c096cabd03329d7be5562c5e14798aa39ed24b474157cef5e85ab9e49ef1\"),\n",
    "  \"small\":\n",
    "    (\"ce1277d8f1ee5a0ef0e171469089c18f5233860ceaf9b168049cb9263fd7483c\",\n",
    "      \"6fc8009faa2f00c1c1dfce59feea9b0745eb260a7dd11bee65c8e20843da6eab\"),\n",
    "  \"base\":\n",
    "    (\"52cbb006d3dadd03f6e095a8ca1aca47aecdd75acb4bc74bce1f5c695d0086e6\",\n",
    "      \"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),\n",
    "  \"large\":\n",
    "    (\"070c5ed9ed289581e477741d3b34beffa920db8cf590899d6d2c67fba2a198a6\",\n",
    "      \"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),\n",
    "  \"xlarge\":\n",
    "    (\"c1f5ccab661354fc3a79a10fa99af82f0fbf10ec65cb894a3ae0815f17a889ee\",\n",
    "      \"de3f8a54174130e0cecdc71583354753d557fcf1f4487331558e2a16ba0cfe05\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edcf20",
   "metadata": {},
   "source": [
    "## Set up ImageNet-1k labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334993ee-0d91-4572-9721-03e67af28cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    imagenet_labels = json.load(read_file)\n",
    "\n",
    "MAPPING_DICT = {}\n",
    "LABEL_NAMES = {}\n",
    "for label_id in list(imagenet_labels.keys()):\n",
    "    MAPPING_DICT[imagenet_labels[label_id][0]] = int(label_id)\n",
    "    LABEL_NAMES[int(label_id)] = imagenet_labels[label_id][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ad5447-3e28-4c86-941f-f64b45be603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['val/n03000134/ILSVRC2012_val_00009432.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00018410.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00043280.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00041208.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00014205.JPEG'],\n",
       " [489, 489, 489, 489, 489])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_val_paths = list(paths.list_images(\"val\"))\n",
    "all_val_labels = [MAPPING_DICT[x.split(\"/\")[1]] for x in all_val_paths]\n",
    "\n",
    "all_val_paths[:5], all_val_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124817d",
   "metadata": {},
   "source": [
    "## Preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4f03d8-25d1-4660-9858-1b197425d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model already has a normalization layer inside.\n",
    "def load_and_prepare(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, (256, 256), method=\"bicubic\")\n",
    "    image = tf.image.central_crop(image, 0.875)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d33240",
   "metadata": {},
   "source": [
    "## Prepare `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3518397-2ab0-4d79-adea-ae5f1cb66add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:18:14.992433: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 06:18:20.470898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((all_val_paths, all_val_labels))\n",
    "dataset = dataset.map(load_and_prepare, num_parallel_calls=AUTO).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(AUTO)\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42076a",
   "metadata": {},
   "source": [
    "## Initialize models and run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f503707-6e94-433b-802a-e56dc51bcae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_tiny.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8ae6e78ce2933352b1ef4008e6dd2f17bc40771563877d156bc6426c7cf503ff so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_tiny.h5\n",
      "114737152/114735104 [==============================] - 1s 0us/step\n",
      "114745344/114735104 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:18:32.383205: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-05-06 06:18:38.069504: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 88s 389ms/step - loss: 0.0000e+00 - accuracy: 0.8131\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_small.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of ce1277d8f1ee5a0ef0e171469089c18f5233860ceaf9b168049cb9263fd7483c so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_small.h5\n",
      "201637888/201633160 [==============================] - 1s 0us/step\n",
      "201646080/201633160 [==============================] - 1s 0us/step\n",
      "196/196 [==============================] - 89s 428ms/step - loss: 0.0000e+00 - accuracy: 0.8239\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_base.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 52cbb006d3dadd03f6e095a8ca1aca47aecdd75acb4bc74bce1f5c695d0086e6 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_base.h5\n",
      "355033088/355031056 [==============================] - 1s 0us/step\n",
      "355041280/355031056 [==============================] - 1s 0us/step\n",
      "196/196 [==============================] - 117s 566ms/step - loss: 0.0000e+00 - accuracy: 0.8536\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_large.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 070c5ed9ed289581e477741d3b34beffa920db8cf590899d6d2c67fba2a198a6 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_large.h5\n",
      "791748608/791747368 [==============================] - 2s 0us/step\n",
      "791756800/791747368 [==============================] - 2s 0us/step\n",
      "196/196 [==============================] - 175s 858ms/step - loss: 0.0000e+00 - accuracy: 0.8636\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_xlarge.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of c1f5ccab661354fc3a79a10fa99af82f0fbf10ec65cb894a3ae0815f17a889ee so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications-temp/convnext/convnext_xlarge.h5\n",
      "1401462784/1401457568 [==============================] - 5s 0us/step\n",
      "1401470976/1401457568 [==============================] - 5s 0us/step\n",
      "196/196 [==============================] - 238s 1s/step - loss: 0.0000e+00 - accuracy: 0.8673\n"
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_CONFIGS:\n",
    "    config = MODEL_CONFIGS.get(model_name)\n",
    "    model = convnext.ConvNeXt(\n",
    "        **config,\n",
    "        include_top=True\n",
    "    )\n",
    "    checkpoint_path = os.path.join(BASE_WEIGHTS_PATH, f\"convnext_{model_name}.h5\")\n",
    "    print(f\"Fetching checkpoint from {checkpoint_path}.\")\n",
    "    \n",
    "    file_hash = WEIGHTS_HASHES.get(model_name)[0]\n",
    "    weights_path = keras.utils.get_file(\n",
    "        f\"convnext_{model_name}.h5\",\n",
    "        checkpoint_path,\n",
    "        cache_subdir=\"models\",\n",
    "        file_hash=file_hash\n",
    "    )\n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(metrics=[\"accuracy\"])\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs_{model_name}\")\n",
    "    \n",
    "    _, accuracy = model.evaluate(dataset, callbacks=[tb_callback])\n",
    "    accuracy = round(accuracy * 100, 4)\n",
    "    print(f\"{model_name}: {accuracy}%.\", file=open(f\"{model_name}.txt\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
